{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"428ab23ee454\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"9afoeuE7RaeqJBo8lKsKiA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.4.3\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.3.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   539  100   539    0     0   4535      0 --:--:-- --:--:-- --:--:--  4567\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "# Run Elastic Search 8.4.3, and get the cluster information. If you run it on localhost\n",
    "# What's the version.build_hash value?\n",
    "\n",
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "# hich function do you use for adding your data to elastic?\n",
    "# Answer: Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:54<00:00, 17.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#create index settings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    # input the data to elastic search\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, filter, num_of_results):\n",
    "    search_query = {\n",
    "        \"size\": num_of_results, # number of results\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"], # question boost 4\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": filter\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=\"course-questions\", body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    # print(response)\n",
    "    for hit in response['hits']['hits']:\n",
    "        # result_docs.append(hit['_source']),\n",
    "        result_docs.append(hit)\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score: 75.54128\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "# We will execute a query \"How do I execute a command in a running docker container?\".\n",
    "# Use only question and text fields and give question a boost of 4, and use \"type\": \"best_fields\".\n",
    "\n",
    "# What's the score for the top ranking result?\n",
    "\n",
    "query = 'How do I execute a command in a running docker container?'\n",
    "result = elastic_search(query, \"data-engineering-zoomcamp\", 5)\n",
    "print(f\"Top Score: {result[0]['_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third question: How do I copy files from a different folder into docker container’s working directory?\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "# Now let's only limit the questions to machine-learning-zoomcamp\n",
    "# Return 3 results. What's the 3rd question returned by the search engine?\n",
    "\n",
    "query = 'How do I execute a command in a running docker container?'\n",
    "search_result = elastic_search(query, \"machine-learning-zoomcamp\",3)\n",
    "print(f\"The third question: {search_result[2]['_source']['question']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the prompt: 1637\n"
     ]
    }
   ],
   "source": [
    "# question 5\n",
    "#  Take the records returned from Elasticsearch in Q4 and use this template to build the context. \n",
    "# Separate context entries by two linebreaks (\\n\\n)\n",
    "# Now use the context you just created along with the \"How do I execute a command in a \n",
    "# running docker container?\" question to construct a prompt using the template below:\n",
    "\n",
    "# What's the length of the resulting prompt? (use the len function)\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['_source']['section']}\\nquestion: {doc['_source']['question']}\\nanswer: {doc['_source']['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(query, search_result)\n",
    "\n",
    "print(f\"length of the prompt: {len(prompt)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens that we have from our prompt there are:356\n"
     ]
    }
   ],
   "source": [
    "#question 6\n",
    "\n",
    "#When we use the OpenAI Platform, we're charged by the number of tokens we send in our prompt and receive in the response.\n",
    "# The OpenAI python package uses tiktoken for tokenization:\n",
    "# Let's calculate the number of tokens in our query:\n",
    "# Use the encode function. How many tokens does our prompt have?\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "print(f\"tokens that we have from our prompt there are:{len(encoding.encode(prompt))}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ce43836c8d3287a06e199a1efd6974587c1d8c7cdf961feda0708cd09e2869c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
